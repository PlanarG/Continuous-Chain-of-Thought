from typing import List

def tokenizer(
    sentences: List[str],
    max_length: int,
):
    pass